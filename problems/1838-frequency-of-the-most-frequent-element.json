{
  "title": "Frequency of the Most Frequent Element",
  "problem_id": "1966",
  "frontend_id": "1838",
  "difficulty": "Medium",
  "problem_slug": "frequency-of-the-most-frequent-element",
  "topics": [
    "Array",
    "Binary Search",
    "Greedy",
    "Sliding Window",
    "Sorting",
    "Prefix Sum"
  ],
  "description": "The frequency of an element is the number of times it occurs in an array.\nYou are given an integer array nums and an integer k. In one operation, you can choose an index of nums and increment the element at that index by 1.\nReturn the maximum possible frequency of an element after performing at most k operations.\nExample 1:\nExample 2:\nExample 3:\nConstraints:",
  "examples": [
    {
      "example_num": 1,
      "example_text": "Input: nums = [1,2,4], k = 5\nOutput: 3\nExplanation: Increment the first element three times and the second element two times to make nums = [4,4,4].\n4 has a frequency of 3.",
      "images": []
    },
    {
      "example_num": 2,
      "example_text": "Input: nums = [1,4,8,13], k = 5\nOutput: 2\nExplanation: There are multiple optimal solutions:\n- Increment the first element three times to make nums = [4,4,8,13]. 4 has a frequency of 2.\n- Increment the second element four times to make nums = [1,8,8,13]. 8 has a frequency of 2.\n- Increment the third element five times to make nums = [1,4,13,13]. 13 has a frequency of 2.",
      "images": []
    },
    {
      "example_num": 3,
      "example_text": "Input: nums = [3,9,6], k = 2\nOutput: 1",
      "images": []
    }
  ],
  "constraints": [
    "1 <= nums.length <= 105",
    "1 <= nums[i] <= 105",
    "1 <= k <= 105"
  ],
  "follow_ups": [],
  "hints": [
    "Note that you can try all values in a brute force manner and find the maximum frequency of that value.",
    "To find the maximum frequency of a value consider the biggest elements smaller than or equal to this value"
  ],
  "code_snippets": {
    "cpp": "class Solution {\npublic:\n    int maxFrequency(vector<int>& nums, int k) {\n        \n    }\n};",
    "java": "class Solution {\n    public int maxFrequency(int[] nums, int k) {\n        \n    }\n}",
    "python": "class Solution(object):\n    def maxFrequency(self, nums, k):\n        \"\"\"\n        :type nums: List[int]\n        :type k: int\n        :rtype: int\n        \"\"\"\n        ",
    "python3": "class Solution:\n    def maxFrequency(self, nums: List[int], k: int) -> int:\n        ",
    "c": "int maxFrequency(int* nums, int numsSize, int k) {\n    \n}",
    "csharp": "public class Solution {\n    public int MaxFrequency(int[] nums, int k) {\n        \n    }\n}",
    "javascript": "/**\n * @param {number[]} nums\n * @param {number} k\n * @return {number}\n */\nvar maxFrequency = function(nums, k) {\n    \n};",
    "typescript": "function maxFrequency(nums: number[], k: number): number {\n    \n};",
    "php": "class Solution {\n\n    /**\n     * @param Integer[] $nums\n     * @param Integer $k\n     * @return Integer\n     */\n    function maxFrequency($nums, $k) {\n        \n    }\n}",
    "swift": "class Solution {\n    func maxFrequency(_ nums: [Int], _ k: Int) -> Int {\n        \n    }\n}",
    "kotlin": "class Solution {\n    fun maxFrequency(nums: IntArray, k: Int): Int {\n        \n    }\n}",
    "dart": "class Solution {\n  int maxFrequency(List<int> nums, int k) {\n    \n  }\n}",
    "golang": "func maxFrequency(nums []int, k int) int {\n    \n}",
    "ruby": "# @param {Integer[]} nums\n# @param {Integer} k\n# @return {Integer}\ndef max_frequency(nums, k)\n    \nend",
    "scala": "object Solution {\n    def maxFrequency(nums: Array[Int], k: Int): Int = {\n        \n    }\n}",
    "rust": "impl Solution {\n    pub fn max_frequency(nums: Vec<i32>, k: i32) -> i32 {\n        \n    }\n}",
    "racket": "(define/contract (max-frequency nums k)\n  (-> (listof exact-integer?) exact-integer? exact-integer?)\n  )",
    "erlang": "-spec max_frequency(Nums :: [integer()], K :: integer()) -> integer().\nmax_frequency(Nums, K) ->\n  .",
    "elixir": "defmodule Solution do\n  @spec max_frequency(nums :: [integer], k :: integer) :: integer\n  def max_frequency(nums, k) do\n    \n  end\nend"
  },
  "solution": "[TOC]\n\n## Solution\n\n---\n\n### Approach 1: Sliding Window\n\n**Intuition**\n\nIn this problem, we want to make as many elements as we can equal using `k` increments.\n\nLet's say that we choose a number `target` and want to maximize its frequency. Intuitively, the elements that we would increment would be the elements that are closest to `target` (and less than `target`, since we can only increment).\n\nSo what number should we choose for `target`? The optimal `target` will already exist in the array. Why?\n\n- Assume `target` is in `nums`, but `target - 1` and `target + 1` are not in `nums`. Let's say that we can increment `x` elements to be equal to `target` using at most `k` operations. We will prove that making `target - 1` or `target + 1` the most frequent element does not lead to better results.\n\n![example](../Figures/1838/1.png)- It would be pointless to instead try to make `target + 1` the most frequent element, since this would cost us `x` extra operations and we would not improve on our answer. The same goes for even larger elements `target + 2` and etc.\n\n![example](../Figures/1838/2.png)- What about `target - 1`? Compared with making `target` the most frequent element, we would lose the values representing these `target`s from our max frequency, but we would save `x` operations which we could potentially use to increment more than one extra element and thus improve our answer.\n\n![example](../Figures/1838/3.png)- The above statement is true, but meaningless! Consider the greatest element in `nums` that is less than `target`. That is, if we were to sort `nums`, consider the element that comes right before `target`. If we were to instead consider this element as the target, we would save more than `x` operations without negatively affecting the frequency relative to considering `target - 1`.\n\n![example](../Figures/1838/4.png)- In summary, for any given number `absent` that is not in `nums`, consider the greatest number in `nums` smaller than `absent` as `smallerTarget`. The number of operations to raise some number of elements to `smallerTarget` will always be less than the number of steps needed to raise them to `absent`.\n- Thus, the optimal value of `target` must exist in `nums`. We can iterate over `nums` and consider each element as `target`.\n\nFor a given value of `target`, how can we efficiently check the frequency we could achieve? As we mentioned at the start, we would want to increment elements that are closest to `target`. As such, we will start by sorting `nums` so that as we iterate over the elements, we know the elements closest to `target` are just to the left of `target`.\n\nNow that `nums` is sorted, consider the first element to the left of `target` as `smaller`. As `smaller` is the closest element to `target`, we want to increment it to equal `target`. This will cost us `target - smaller` operations. Now, consider the next element to the left as `smaller2`. Now this is the element closest to `target`, so we increment it using `target - smaller2` operations. We continue this process until we run out of operations.\n\nAs you can see, the number of operations required is simply the difference between `target` and the numbers we are incrementing. Let's say that the final frequency of `target` was `4`. We would have a sum of `4 * target`. The number of operations would be this sum minus the sum of the elements before we incremented them. Consider the following example:\n\n![example](../Figures/1838/5.png)> If you aren't already familiar with the sliding window technique, we highly recommend reading [this free article](https://leetcode.com/explore/interview/card/leetcodes-interview-crash-course-data-structures-and-algorithms/703/arraystrings/4502/) from LeetCode's official DSA course, where sliding window is explained in detail with multiple examples.\n\nThis brings us to our solution. We will use a sliding window over the sorted `nums`. For each element `nums[right]`, we will treat `target` as this element and try to make every element in our window equal to `target`.\n\nThe size of the window is `right - left + 1`. That means we would have a final sum of `(right - left + 1) * target`. If we track the sum of our window in a variable `curr`, then we can calculate the required operations as `(right - left + 1) * target - curr`. If it requires more than `k` operations, we must shrink our window. Like in all sliding window problems, we will use a `while` loop to shrink our window by incrementing `left` until `k` operations are sufficient.\n\nOnce the `while` loop ends, we know that we can make all elements in the window equal to `target`. We can now update our answer with the current window size. The final answer will be the largest valid window we find after iterating `right` over the entire input.\n\n**Algorithm**\n\n1. Sort `nums`.\n2. Initialize the following integers:\n    - `left = 0`, the left pointer.\n    - `ans = 0`, the best answer we have seen so far.\n    - `curr = 0`, the sum of the elements currently in our window.\n3. Iterate `right` over the indices of `nums`:\n    - Consider `target = nums[right]`.\n    - Add `target` to `curr`.\n    - While the size of the window `right - left + 1` multiplied by `target`, minus `curr` is greater than `k`:\n        - Subtract `nums[left]` from `curr`.\n        - Increment `left`.\n    - Update `ans` with the current window size if it is larger.\n4. Return `ans`.\n\n**Implementation**\n\n> Be careful! Given the constraints, we may run into integer overflow. Use `long` accordingly in Java and C++ (Python doesn't have overflow).**Complexity Analysis**\n\nGiven $$n$$ as the length of `nums`,\n\n* Time complexity: $$O(n \\cdot \\log{}n)$$\n\n    Despite the while loop, each iteration of the for loop is amortized $$O(1)$$. The while loop only runs $$O(n)$$ times across all iterations. This is because each iteration of the while loop increments `left`. As `left` can only increase and cannot exceed `n`, the while loop never performs more than `n` iterations total. This means the sliding window process runs in $$O(n)$$.\n\n    However, we need to sort the array, which costs $$O(n \\cdot \\log{}n)$$.\n\n* Space Complexity: $$O(\\log n)$$ or $$O(n)$$\n\n    We only use a few integer variables, but some space is used to sort.\n\n    The space complexity of the sorting algorithm depends on the implementation of each programming language:\n    * In Java, Arrays.sort() for primitives is implemented using a variant of the Quick Sort algorithm, which has a space complexity of $$O(\\log n)$$\n    * In C++, the sort() function provided by STL uses a hybrid of Quick Sort, Heap Sort and Insertion Sort, with a worst case space complexity of $$O(\\log n)$$\n    * In Python, the sort() function is implemented using the Timsort algorithm, which has a worst-case space complexity of $$O(n)$$---\n\n### Approach 2: Advanced Sliding Window\n\n**Intuition**\n\n> This approach is an extension of the previous one.\n\nNotice that the only thing we care about is the **length** of the longest window. We don't need to know what the window itself is. As we slide the window over the array, let's say we find a valid window with a length of `len`. **We no longer care about any windows with lengths less than `len`**, because they could not possibly improve on our answer.\n\nThe purpose of the while loop in the previous approach is to shrink the window until it is valid again. In this approach, we will not shrink the window - we will just try to grow it as large as we can.\n\nWe will keep the same condition in the while loop that checks if the current window `[left, right]` is valid, but instead of using a while loop, we will just use an if statement. This means `left` never increases by more than `1` per iteration. Because `right` also increases by `1` per iteration, if we cannot find a valid window, we will simply be sliding a window with static size across the array.\n\nHowever, if we add an element `nums[right]` to the window and the window is valid, then the if statement will not trigger, and `left` will not be incremented. Thus, we will increase our window size by `1`. In this scenario, it implies the current window `[left, right]` is the best window we have seen so far.\n\n> As you can see, it is actually impossible for our window size to decrease, since each iteration increases `right` by `1` and `left` by either `0` or `1`.\n\nBecause our window size cannot decrease, it also means that the size of the window always represents the length of the best window we have found so far - analogous to `ans` from the previous approach.\n\nAt the end of the iteration, the size of our window is `n - left`. We return this as the answer.\n\n**Algorithm**\n\n1. Sort `nums`.\n2. Initialize the following integers:\n    - `left = 0`, the left pointer.\n    - `curr = 0`, the sum of the elements currently in our window.\n3. Iterate `right` over the indices of `nums`:\n    - Consider `target = nums[right]`.\n    - Add `target` to `curr`.\n    - If the size of the window `right - left + 1` multiplied by `target`, minus `curr` is greater than `k`:\n        - Subtract `nums[left]` from `curr`.\n        - Increment `left`.\n4. Return `nums.length - left`.\n\n**Implementation****Complexity Analysis**\n\nGiven $$n$$ as the length of `nums`,\n\n* Time complexity: $$O(n \\cdot \\log{}n)$$\n\n    Each iteration of the for loop costs $$O(1)$$. This means the sliding window process runs in $$O(n)$$.\n\n    However, we need to sort the array, which costs $$O(n \\cdot \\log{}n)$$.\n\n* Space Complexity: $$O(\\log n)$$ or $$O(n)$$\n\n    We only use a few integer variables, but some space is used to sort.\n\n    The space complexity of the sorting algorithm depends on the implementation of each programming language:\n    * In Java, Arrays.sort() for primitives is implemented using a variant of the Quick Sort algorithm, which has a space complexity of $$O(\\log n)$$\n    * In C++, the sort() function provided by STL uses a hybrid of Quick Sort, Heap Sort and Insertion Sort, with a worst case space complexity of $$O(\\log n)$$\n    * In Python, the sort() function is implemented using the Timsort algorithm, which has a worst-case space complexity of $$O(n)$$---\n\n### Approach 3: Binary Search\n\n**Intuition**\n\n> Note: the previous two approaches are the optimal solutions and are sufficient to solve the problem. Here, we will look at another unique way to approach the problem for the sake of completeness.\n\nGiven an index `i`, if we treat `nums[i]` as `target`, we are concerned with how many elements on the left we can take. In the earlier approaches, we used a sliding window. In this approach, we will directly find the left-most index of these elements using binary search.\n\nLet's say that `best` is the index of the furthest element to the left that we could increment to `target = nums[i]`. Note that here, `best` is analogous to what `left` was after the while loop finished in the first approach. How do we find `best`?\n\nThe value of `best` must be in the range `[0, i]`. We will perform a binary search on this range. For a given index `mid`:\n\n- The number of elements in the window would be `count = i - mid + 1`.\n- Thus, the final sum after making every element in the window equal to `target` would be `finalSum = count * target`.\n- The original sum of the elements is the sum of the elements from index `mid` to index `i`. We can use a prefix sum to find this `originalSum`.\n- Thus, the number of operations we need is `operationsRequired = finalSum - originalSum`.\n- If `operationsRequired > k`, it's impossible to include the index `mid`. We update `left = mid + 1`.\n- Otherwise, the task is possible and we should look for a better index. We update `best = mid` and `right = mid - 1`.\n\nEssentially, we are binary searching the left bound from the first approach for a given right bound `i`. If we pre-process a prefix sum, then for each `mid`, we have all the necessary information to find `operationsRequired`.\n\n**Algorithm**\n\n1. Define a function `check(i)`:\n    - Initialize the following integers:\n        - `target = nums[i]`, the current target.\n        - `left = 0`, the left bound of the binary search.\n        - `right = i`, the right bound of the binary search.\n        - `best = i`, the best (furthest left) index that we can increment to `target`.\n    - While `left <= right`\n        - Calculate `mid = (left + right) / 2`.\n        - Calculate `count = i - mid + 1`.\n        - Calculate `finalSum = count * target`.\n        - Calculate `originalSum = prefix[i] - prefix[mid] + nums[mid]`.\n        - Calculate `operationsRequired = finalSum - originalSum`.\n        - If `operationsRequired > k`, move `left = mid + 1`.\n        - Otherwise, update `best = mid` and `right = mid - 1`.\n    - Return `i - best + 1`.\n2. Sort `nums`.\n3. Create a `prefix` sum of `nums`.\n4. Initialize `ans = 0`.\n5. Iterate `i` over the indices of `nums`:\n    - Update `ans` with `check(i)` if it is larger.\n6. Return `ans`.\n\n**Implementation**\n\n> Be careful! Given the constraints, we may run into integer overflow. Use `long` accordingly in Java and C++ (Python doesn't have overflow).**Complexity Analysis**\n\nGiven $$n$$ as the length of `nums`,\n\n* Time complexity: $$O(n \\cdot \\log{}n)$$\n\n    First, we sort `nums` which costs $$O(n \\cdot \\log{}n)$$.\n\n    Next, we iterate over the indices of `nums`. For each of the $$O(n)$$ indices, we call `check`, which costs up to $$O(\\log{}n)$$ as its a binary search over the array's elements. The total cost is $$O(n \\cdot \\log{}n)$$.\n\n* Space complexity: $$O(n)$$\n\n    The `prefix` array uses $$O(n)$$ space.---"
}