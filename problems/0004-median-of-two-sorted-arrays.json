{
  "title": "Median of Two Sorted Arrays",
  "problem_id": "4",
  "frontend_id": "4",
  "difficulty": "Hard",
  "problem_slug": "median-of-two-sorted-arrays",
  "topics": [
    "Array",
    "Binary Search",
    "Divide and Conquer"
  ],
  "description": "Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays.\nThe overall run time complexity should be O(log (m+n)).\nExample 1:\nExample 2:\nConstraints:",
  "examples": [
    {
      "example_num": 1,
      "example_text": "Input: nums1 = [1,3], nums2 = [2]\nOutput: 2.00000\nExplanation: merged array = [1,2,3] and median is 2.",
      "images": []
    },
    {
      "example_num": 2,
      "example_text": "Input: nums1 = [1,2], nums2 = [3,4]\nOutput: 2.50000\nExplanation: merged array = [1,2,3,4] and median is (2 + 3) / 2 = 2.5.",
      "images": []
    }
  ],
  "constraints": [
    "nums1.length == m",
    "nums2.length == n",
    "0 <= m <= 1000",
    "0 <= n <= 1000",
    "1 <= m + n <= 2000",
    "-106 <= nums1[i], nums2[i] <= 106"
  ],
  "follow_ups": [],
  "hints": [],
  "code_snippets": {
    "cpp": "class Solution {\npublic:\n    double findMedianSortedArrays(vector<int>& nums1, vector<int>& nums2) {\n        \n    }\n};",
    "java": "class Solution {\n    public double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        \n    }\n}",
    "python": "class Solution(object):\n    def findMedianSortedArrays(self, nums1, nums2):\n        \"\"\"\n        :type nums1: List[int]\n        :type nums2: List[int]\n        :rtype: float\n        \"\"\"\n        ",
    "python3": "class Solution:\n    def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -> float:\n        ",
    "c": "double findMedianSortedArrays(int* nums1, int nums1Size, int* nums2, int nums2Size) {\n    \n}",
    "csharp": "public class Solution {\n    public double FindMedianSortedArrays(int[] nums1, int[] nums2) {\n        \n    }\n}",
    "javascript": "/**\n * @param {number[]} nums1\n * @param {number[]} nums2\n * @return {number}\n */\nvar findMedianSortedArrays = function(nums1, nums2) {\n    \n};",
    "typescript": "function findMedianSortedArrays(nums1: number[], nums2: number[]): number {\n    \n};",
    "php": "class Solution {\n\n    /**\n     * @param Integer[] $nums1\n     * @param Integer[] $nums2\n     * @return Float\n     */\n    function findMedianSortedArrays($nums1, $nums2) {\n        \n    }\n}",
    "swift": "class Solution {\n    func findMedianSortedArrays(_ nums1: [Int], _ nums2: [Int]) -> Double {\n        \n    }\n}",
    "kotlin": "class Solution {\n    fun findMedianSortedArrays(nums1: IntArray, nums2: IntArray): Double {\n        \n    }\n}",
    "dart": "class Solution {\n  double findMedianSortedArrays(List<int> nums1, List<int> nums2) {\n    \n  }\n}",
    "golang": "func findMedianSortedArrays(nums1 []int, nums2 []int) float64 {\n    \n}",
    "ruby": "# @param {Integer[]} nums1\n# @param {Integer[]} nums2\n# @return {Float}\ndef find_median_sorted_arrays(nums1, nums2)\n    \nend",
    "scala": "object Solution {\n    def findMedianSortedArrays(nums1: Array[Int], nums2: Array[Int]): Double = {\n        \n    }\n}",
    "rust": "impl Solution {\n    pub fn find_median_sorted_arrays(nums1: Vec<i32>, nums2: Vec<i32>) -> f64 {\n        \n    }\n}",
    "racket": "(define/contract (find-median-sorted-arrays nums1 nums2)\n  (-> (listof exact-integer?) (listof exact-integer?) flonum?)\n  )",
    "erlang": "-spec find_median_sorted_arrays(Nums1 :: [integer()], Nums2 :: [integer()]) -> float().\nfind_median_sorted_arrays(Nums1, Nums2) ->\n  .",
    "elixir": "defmodule Solution do\n  @spec find_median_sorted_arrays(nums1 :: [integer], nums2 :: [integer]) :: float\n  def find_median_sorted_arrays(nums1, nums2) do\n    \n  end\nend"
  },
  "solution": "[TOC]\n\n## Video Solution\n\n---## Solution\n\n--- \n\n### Overview\n\nIn this problem, we are given two **sorted** arrays, `nums1` and `nums2`. We need to return the **median** of these two arrays.\n\n---\n\n### Approach 1: Merge Sort\n\n#### Intuition   \n\nLet's start with the straightforward approach. If we put the elements of two arrays in one array `A` and arrange them in order. Assume the merged arrays has a length of `n`, then the median is:\n    - `A[n / 2]`, if `n` is odd.\n    - The average of `A[n / 2]` and `A[n / 2 + 1]`, if `n` is even.\n\nHowever, we do not really need to merge and sort these arrays. Note that both arrays are already sorted, so the smallest element is either the first element of `nums1` or the first element of `nums2`. Therefore, we can set two pointers `p1` and `p2` at the start of each array, then we can get the smallest element from the `nums1` and `nums2` by comparing the values `nums1[p1]` and `nums2[p2]`.\n\nPlease refer to the following slide as an example:\n\n!?!../Documents/4/s1.json:601,301!?!#### Algorithm\n\n1) Get the total size of two arrays `m + n`\n    - If `m + n` is odd, we are looking for the `(m + n) / 2`-th element.\n    - If `m + n` is even, we are looking for the average of the `(m + n) / 2`-th and the `(m + n) / 2 + 1`-th elements.\n2) Set two pointers `p1` and `p2` at the beginning of arrays `nums1` and `nums2`. \n3) If both `p1` and `p2` are in bounds of the arrays, compare the values at `p1` and `p2`:\n\n    - If `nums1[p1]` is smaller than `nums2[p2]`, we move `p1` one place to the right.\n    - Otherwise, we move `p2` one place to the right.\n\n    If `p1` is outside `nums1`, just move `p2` one place to the right.     \n    If `p2` is outside `nums2`, just move `p1` one place to the right.\n4) Get the target elements and calculate the median:\n    - If `m + n` is odd, repeat step 3 by `(m + n + 1) / 2` times and return the element from the last step.\n    - If `m + n` is even, repeat step 3 by `(m + n) / 2 + 1` times and return the average of the elements from the last two steps.\n\n\n\n#### Implementation#### Complexity Analysis\n\nLet $$m$$ be the size of array `nums1` and $$n$$ be the size of array `nums2`.\n\n* Time complexity: $$O(m + n)$$\n\n    - We get the smallest element by comparing two values at `p1` and `p2`, it takes $$O(1)$$ to compare two elements and move the corresponding pointer to the right.\n    - We need to traverse half of the arrays before reaching the median element(s).\n    - To sum up, the time complexity is $$O(m + n)$$.\n    \n\n* Space complexity: $$O(1)$$\n\n    - We only need to maintain two pointers `p1` and `p2`.---\n\n### Approach 2: Binary Search, Recursive\n\n#### Intuition   \n\nBecause the inputs are sorted arrays and the problem asks for a logarithmic time limit, we strongly feel that binary search (or a similar approach) is a promising method. While we're not sure how to cast the same pattern as a normal binary search on this problem, let's go over some steps of a regular binary search and see if we can get any inspiration. (If you are not familiar with binary search, you can refer to our [Binary Search Explore Card](https://leetcode.com/explore/learn/card/binary-search/))\n\n\nHere we use binary search to find `target` in a sorted array `A`:\n\n- Locate the middle index (element) of `A`.\n- Compare the value of the middle element with `target`.\n- Reduce the search space by cutting the current array in half and discarding the half which is guaranteed not to contain `target`.\n\n- Repeat the above process until we either empty the array (move to half a the length of 0) or find `target`.\n\n\n\n![img](../Figures/4/bs.png)\n\nAt each step, the search space is cut in half, so we can quickly get the result. Now back to this problem where we have two sorted arrays. For the sake of convenience, let's call them `A` and `B`. \n\n![img](../Figures/4/2.png)\n\nSimilarly, we can get and compare their middle values `A_mid` and `B_mid`. Without loss of generality in this example we assume `A_mid <= B_mid` initially, as shown in the yellow boxes. \n\n\n\n![img](../Figures/4/3.png)\n\n**What does this comparison imply?**\n\nIt implies that we can compare sections of `A` and `B`.\n\n> For the rest of this article, we will use $$\\le$$ to represent the relative magnitude of values in arrays. For example, $$A_{\\text{left}} \\le A_{\\text{right}}$$ means that every element in $A_{\\text{left}}$ is no larger than any element in $A_{\\text{right}}$. We also 'compare' elements in an array with a single element similarly, for example, $$A_{\\text{left}} \\le A_{\\text{mid}}$$ means that every element in $A_{\\text{left}}$ is no larger than the element $A_{\\text{mid}}$. \nThis may not be the most standard way of expressing it, but is easy enough to understand.\n\nRecall that both arrays are sorted, so we know that:\n- $$A_{\\text{left}} \\le A_{\\text{mid}}$$\n- $$B_{\\text{mid}} \\le B_{\\text{right}}$$\n\nCombine these observations with the comparison we just made:\n\n\n$$A_{\\text{mid}} \\le B_{\\text{mid}}$$\n\nWe have the following result:\n\n$$A_{\\text{left}} \\le A_{\\text{mid}} \\le B_{\\text{mid}} \\le B_{\\text{right}}$$\n\nThus, \n\n$$A_{\\text{left}} \\le B_{\\text{right}}$$\n\nAs shown in the picture below:\n\n![img](../Figures/4/4.png)\n\nSince `A` is sorted, we know that $$A_{\\text{left}} \\le A_{\\text{right}}$$.\n\n![img](../Figures/4/5.png)\n\n\nNow we know that `A_left` is smaller than two halves: `A_right` and `B_right`. Although we still don't know where exactly these elements are, what we do know is **`A_left` doesn't intersect with `A_right + B_right`**! There is an invisible boundary between the `A_left` segment and the mixed segment `A_right + B_right`. As shown in the picture below, the dashed line divides all sorted elements into two halves.\n\n\n\n![img](../Figures/4/6.png)\n\n\nWe can apply all the same logic to the mixed segment $$A_{\\text{left}}$$ + $$B_{\\text{left}}$$ and $$B_{\\text{right}}$$, which also do not intersect. You can try to prove it yourself as an exercise.\n\n\n![img](../Figures/4/7.png)\n\n\nIt looks somewhat clearer, we have clearly separated some subarrays. How do we continue to leverage this knowledge and use the cut-in-half method repeatedly?**The following step is the most important one.**\n\n\nRemember that we are looking for the median of `sorted A + B` which is one or two target values. We regard the index of the target value in the `sorted(A + B)` as `k`. For example: \n\n- If the lengths of `A` and `B` are `6` and `5`, the target index is `k = (6 + 5 + 1) / 2 = 6`, we shall look for the 6th smallest element. \n\n- If the lengths of `A` and `B` are `6` and `6`, the target indexes are `k = (6 + 6) / 2 = 6` and `k + 1 = 7`, we shall look for the 6th and the 7th smallest elements. \n\n\n\nDepending on whether the total number of elements is odd or even, we need the $$k^{th}$$ (and maybe the $$(k + 1)^{th}$$) elements. What matters is that we set an index `k` at the beginning and we want to find the $$k^{th}$$ smallest element using the Binary Search-like algorithm discussed previously (for convenience, we will discuss only the $$k^{th}$$ element for now).\n\n\n\nHowever, during the Binary Search-like algorithm, we keep removing one half of an array, so the index `k` might not stay unchanged. Suppose we removed `3` elements that are smaller than the original $$k^{th}$$ smallest element, we shall look for the $$(k-3)^{th}$$ smallest element from the **remaining** arrays.\n\n\n![img](../Figures/4/exp_1.png)\n\nMore specifically:\n\nIf `k` is larger than half the total number of elements in `sorted(A + B)`, it means that the $$k^{th}$$ element is in the second (larger) half of `sorted(A + B)`, thus $$A_{\\text{left}}$$ (or $$B_{\\text{left}}$$, the smaller of the two smaller sections according to the comparison) is guaranteed not to contain this element, and we can safely cut this half, and reduce `k` by the length of the removed half.\n\n\nIf `k` is not larger than half the total number of elements in `sorted(A + B)`, it means that the $$k^{th}$$ element is in the first (smaller) half of `sorted(A + B)`, thus $$B_{\\text{right}}$$ (or $$A_{\\text{right}}$$, the larger of the two larger sections according to the comparison) is guaranteed not to contain this element, and we can safely discard it. Note that we don't need to modify `k` this time, since we removed one larger half that doesn't affect the order of the $$k^{th}$$ smallest element.\n\n\n\nWe can continue our search like above in the **remaining** arrays. The long arrow that starts from the bottom and points to the top-left indicates that we are repeating the process. Once we cut off part of either `A` or `B`, we regard the remaining arrays as modified `A` and `B` and restart this algorithm. Note that the following picture represents one case only: we consider the case that `a_value < b_value`, thus we remove either the smaller half of `A` or the larger half of `B`. If the comparison result is `a_value >= b_value`, we shall remove either the smaller half of `B` or the larger half of `A`.\n\n![img](../Figures/4/9.png)\n\n\nThat's it. We cut one of the two arrays in half at each step, so this approach has a logarithmic time complexity which we will discuss in detail later.\n\n\n> One more thing!\n\nIn the previous picture, we repeat all processes using the modified arrays, but this is just for the sake of understanding. We won't create copies of two arrays repeatedly, because that would introduce a linear time complexity at least. Instead, we just treat a part of the original array as the modified array for the next step, so that we can repeat the process on the original array without making any duplication. To do this, we need to maintain four pointers, two pointers for each array, e.g., `a_start` and `a_end` represent an inclusive range `[a_start, a_end]` of `A`.#### Algorithm\n\nLet's define a function that helps us find the $$k^{th}$$ smallest element from two inclusive ranges `[a_start, a_end]` and `[b_start, b_end]` from arrays `A` and `B`.\n\n\n\n1) If the range (for example, a range of `A`) is empty, in other words `a_start > a_end`, it means all elements in `A` are passed, we just return the `(k - a_start)`-th element from the other array `B`. Vice versa if `b_start > b_end`.\n\n2) Otherwise, get the middle indexes of the two ranges: `a_index = (a_start + a_end) / 2`, `b_index = (b_start + b_end) / 2`.\n3) Get the middle values of the two ranges: `a_value = A[a_index]`, `b_value = B[b_index]`.\n4) Cut one array in half, according to:\n    - If `a_index + b_index < k`, cut one smaller half.\n        - If `a_value < b_value`, cut the smaller half of `A`.\n        - Otherwise, cut the smaller half of `B`.\n    - Otherwise, cut one larger half.\n        - If `b_value < a_value`, cut the larger half of `B`.\n        - Otherwise, cut the larger half of `A`.\n5) Repeat step 1 using the new starting and ending indexes of `A` and `B`.\n\n\nThen we move on to find the median elements, and get the length of both arrays `na = len(A)` and `nb = len(B)`.\n- If the total number of elements in `A` and `B` is odd, we just use the above function to find the middle element, that is `k = (na + nb) / 2`.\n- Otherwise, we use the function to find two middle elements: `k = (na + nb) / 2 - 1` and `k = (na + nb) / 2`, and return their average.\n\n#### Implementation#### Complexity Analysis\n\nLet $$m$$ be the size of array `nums1` and $$n$$ be the size of array `nums2`.\n\n* Time complexity: $$O(\\log(m \\cdot n))$$\n\n\n    - At each step, we cut one half off from either `nums1` or `nums2`. If one of the arrays is emptied, we can directly get the target from the other array in a constant time. Therefore, the total time spent depends on when one of the arrays is cut into an empty array.\n    - In the worst-case scenario, we may need to cut both arrays before finding the target element.\n    - One of the two arrays is cut in half at each step, thus it takes logarithmic time to empty an array. The time to empty two arrays are independent of each other.![img](../Figures/4/tc.png)\n\n    - Therefore, the time complexity is $$O(\\log m + \\log n)$$.\n     $$O(\\log m + \\log n) = O(\\log (m\\cdot n))$$\n    \n\n* Space complexity: $$O(\\log m + \\log n)$$\n\n    - Similar to the analysis on time complexity, the recursion steps depend on the number of iterations before we cut an array into an empty array. In the worst-case scenario, we need $$O(\\log m + \\log n)$$ recursion steps. \n    - However, during the recursive self-call, we only need to maintain 4 pointers: `a_start`, `a_end`, `b_start` and `b_end`. The last step of the function is to call itself, so if tail call optimization is implemented, the call stack always has $$O(1)$$ records.\n\n    - Please refer to [Tail Call](https://en.wikipedia.org/wiki/Tail_call) for more information on tail call optimization.---\n\n### Approach 3: A Better Binary Search\n\n\n#### Intuition   \n\nRecall the previous approach where we perform a binary search over the 'merged' array consisting of `nums1` and `nums2`, resulting in a time complexity of $$O(\\log(m \\cdot n))$$. We could further improve the algorithm by performing the binary search only on the smaller array of `nums1` and `nums2`, thus the time complexity is reduced to $$O(\\log(\\min(m, n)))$$.\n\n\nThe main idea is similar to approach 2, where we need to find a point of partition in both arrays such that the maximum of the smaller half is less than or equal to the minimum of the larger half. \n\n\nHowever, instead of partitioning over the merged arrays, we can only focus on partitioning the smaller array (let's call this array `A`). Suppose the partition index is `partitionA`, we specify that the smaller half contains `(m + n + 1) / 2` elements, and we can use this feature to our advantage by directly making `partitionB` equal to `(m + n + 1) / 2 - partitionA`, thus the smaller halves of both arrays always contain a total of `(m + n + 1) / 2` elements, as shown in the picture below.\n\n![img](../Figures/4/2_0.png)\n\nThe next step is to compare these edge elements.\n\n![img](../Figures/4/2_1.png)\n\nIf both `maxLeftA <= minRightB` and `maxLeftB <= minRightA` hold, it means that we have partitioned arrays at the correct place. \n\n- The smaller half consists of two sections `A_left` and `B_left`\n- THe larger half consists of two sections `A_right` and `B_right`\n\nWe just need to find the maximum value from the smaller half as `max(A[maxLeftA], B[maxLeftB])` and the minimum value from the larger half as `min(A[minRightA], B[minRightB])`. The median value depends on these four boundary values and the total length of the input arrays and we can compute it by situation.\n\n![img](../Figures/4/2_2.png)\n\nIf `maxLeftA > minRightB`, it implies that `maxLeftA` is **too large to be in the smaller half** and we should look for a smaller partition value of `A`. \n\n\n![img](../Figures/4/2_3.png)\n\nOtherwise, it denotes that `minRightA` is **too small to be in the larger half** and we should look for a larger partition value of `A`.\n\n![img](../Figures/4/2_4.png)#### Algorithm\n\n1) Assuming `nums1` to be the smaller array (If `nums2` is smaller, we can swap them). Let `m, n` represent the size of `nums1` and `nums2`, respectively.\n\n2) Define the search space for the partitioning index `partitionA` by setting boundaries as `left = 0` and `right = m`.\n\n3) While `left <= right` holds, do the following.\n\n4) Compute the partition index of `nums1` as `partitionA = (left + right) / 2`. Consequently, the partition index of `nums2` is `(m + n + 1) / 2 - partitionA`.\n\n5) Obtain the edge elements:\n    - Determine the maximum value of the section `A_left` as `maxLeftA = nums1[partitionA - 1]`. If `partitionA - 1 < 0`, set it as `maxLeftA = float(-inf)`.\n    - Determine the minimum value of the section `A_right` as `minRightA = nums1[partitionA]`. If `partitionA >= m`, set it as `minRightA = float(inf)`.\n    - Determine the maximum value of the section `B_left` as `maxLeftB = nums2[partitionB - 1]`. If `partitionB - 1 < 0`, set it as `maxLeftB = float(-inf)`.\n    - Determine the maximum value of the section `B_right` as `minRightB = nums2[partitionB]`. If `partitionB >= n`, set it as `minRightB = float(inf)`.\n\n\n6) Compare and recalculate: Compare `maxLeftA` with `minRightB` and `maxLeftB` with `minRightA`. \n    - If `maxLeftA > minRightB`, it means the `maxLeftA` is too large to be in the smaller half, so we update `right = partitionA - 1` to move to the left half of the search space.\n    - If `maxLeftB > minRightA`, it means that we are too far on the left side for `partitionA` and we need to go to the right half of the search space by updating `left = partitionA + 1`. \n\n    Repeat step 4.\n\n7) When both `maxLeftA <= minRightB` and `maxLeftB <= minRightA` are true:\n    - If `(m + n) % 2 = 0`, the median value is the average of the maximum value of the smaller half and the minimum value of the larger half, given by `answer = (max(maxLeftA, maxLeftB) + min(minRightA, minRightB)) / 2`.\n    - Otherwise, the median value is the maximum value of the smaller half, given by `answer = max(maxLeftA, maxLeftB)`.\n\n\n\n#### Implementation#### Complexity Analysis\n\nLet $$m$$ be the size of array `nums1` and $$n$$ be the size of array `nums2`.\n\n* Time complexity: $$O(\\log(\\min(m, n)))$$\n\n    - We perform a binary search over the smaller array of size $$\\min(m, n)$$.\n\n* Space complexity: $$O(1)$$\n\n    - The algorithm only requires a constant amount of additional space to store and update a few parameters during the binary search."
}