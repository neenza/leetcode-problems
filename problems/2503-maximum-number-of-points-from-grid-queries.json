{
  "title": "Maximum Number of Points From Grid Queries",
  "problem_id": "2588",
  "frontend_id": "2503",
  "difficulty": "Hard",
  "problem_slug": "maximum-number-of-points-from-grid-queries",
  "topics": [
    "Array",
    "Two Pointers",
    "Breadth-First Search",
    "Union Find",
    "Sorting",
    "Heap (Priority Queue)",
    "Matrix"
  ],
  "description": "You are given an m x n integer matrix grid and an array queries of size k.\nFind an array answer of size k such that for each integer queries[i] you start in the top left cell of the matrix and repeat the following process:\nAfter the process, answer[i] is the maximum number of points you can get. Note that for each query you are allowed to visit the same cell multiple times.\nReturn the resulting array answer.\nExample 1:\nExample 2:\nConstraints:",
  "examples": [
    {
      "example_num": 1,
      "example_text": "Input: grid = [[1,2,3],[2,5,7],[3,5,1]], queries = [5,6,2]\nOutput: [5,8,1]\nExplanation: The diagrams above show which cells we visit to get points for each query.",
      "images": [
        "https://assets.leetcode.com/uploads/2025/03/15/image1.png"
      ]
    },
    {
      "example_num": 2,
      "example_text": "Input: grid = [[5,2,1],[1,1,2]], queries = [3]\nOutput: [0]\nExplanation: We can not get any points because the value of the top left cell is already greater than or equal to 3.",
      "images": [
        "https://assets.leetcode.com/uploads/2022/10/20/yetgriddrawio-2.png"
      ]
    }
  ],
  "constraints": [
    "m == grid.length",
    "n == grid[i].length",
    "2 <= m, n <= 1000",
    "4 <= m * n <= 105",
    "k == queries.length",
    "1 <= k <= 104",
    "1 <= grid[i][j], queries[i] <= 106"
  ],
  "follow_ups": [],
  "hints": [
    "The queries are all given to you beforehand so you can answer them in any order you want.",
    "Sort the queries knowing their original order to be able to build the answer array.",
    "Run a BFS on the graph and answer the queries in increasing order."
  ],
  "code_snippets": {
    "cpp": "class Solution {\npublic:\n    vector<int> maxPoints(vector<vector<int>>& grid, vector<int>& queries) {\n        \n    }\n};",
    "java": "class Solution {\n    public int[] maxPoints(int[][] grid, int[] queries) {\n        \n    }\n}",
    "python": "class Solution(object):\n    def maxPoints(self, grid, queries):\n        \"\"\"\n        :type grid: List[List[int]]\n        :type queries: List[int]\n        :rtype: List[int]\n        \"\"\"\n        ",
    "python3": "class Solution:\n    def maxPoints(self, grid: List[List[int]], queries: List[int]) -> List[int]:\n        ",
    "c": "/**\n * Note: The returned array must be malloced, assume caller calls free().\n */\nint* maxPoints(int** grid, int gridSize, int* gridColSize, int* queries, int queriesSize, int* returnSize) {\n    \n}",
    "csharp": "public class Solution {\n    public int[] MaxPoints(int[][] grid, int[] queries) {\n        \n    }\n}",
    "javascript": "/**\n * @param {number[][]} grid\n * @param {number[]} queries\n * @return {number[]}\n */\nvar maxPoints = function(grid, queries) {\n    \n};",
    "typescript": "function maxPoints(grid: number[][], queries: number[]): number[] {\n    \n};",
    "php": "class Solution {\n\n    /**\n     * @param Integer[][] $grid\n     * @param Integer[] $queries\n     * @return Integer[]\n     */\n    function maxPoints($grid, $queries) {\n        \n    }\n}",
    "swift": "class Solution {\n    func maxPoints(_ grid: [[Int]], _ queries: [Int]) -> [Int] {\n        \n    }\n}",
    "kotlin": "class Solution {\n    fun maxPoints(grid: Array<IntArray>, queries: IntArray): IntArray {\n        \n    }\n}",
    "dart": "class Solution {\n  List<int> maxPoints(List<List<int>> grid, List<int> queries) {\n    \n  }\n}",
    "golang": "func maxPoints(grid [][]int, queries []int) []int {\n    \n}",
    "ruby": "# @param {Integer[][]} grid\n# @param {Integer[]} queries\n# @return {Integer[]}\ndef max_points(grid, queries)\n    \nend",
    "scala": "object Solution {\n    def maxPoints(grid: Array[Array[Int]], queries: Array[Int]): Array[Int] = {\n        \n    }\n}",
    "rust": "impl Solution {\n    pub fn max_points(grid: Vec<Vec<i32>>, queries: Vec<i32>) -> Vec<i32> {\n        \n    }\n}",
    "racket": "(define/contract (max-points grid queries)\n  (-> (listof (listof exact-integer?)) (listof exact-integer?) (listof exact-integer?))\n  )",
    "erlang": "-spec max_points(Grid :: [[integer()]], Queries :: [integer()]) -> [integer()].\nmax_points(Grid, Queries) ->\n  .",
    "elixir": "defmodule Solution do\n  @spec max_points(grid :: [[integer]], queries :: [integer]) :: [integer]\n  def max_points(grid, queries) do\n    \n  end\nend"
  },
  "solution": "[TOC]\n\n## Solution\n\n---\n\n### Overview\n\nWe are given an `m x n` matrix `grid` and an array of queries, `queries`. For each query, we attempt to collect as many points as possible while following specific movement rules that dictate how far we can traverse the grid. \n\nFor each `queries[i]`, we begin at the top-left corner of the grid. We are allowed to move in four directions: up, down, left, and right. The primary condition governing movement is the comparison between `queries[i]` and the value of the current cell:\n\n1. If `queries[i]` is strictly greater than the value of the current cell, then:  \n   - If this is the first time visiting the cell, we earn one point.  \n   - We can then move to any of the adjacent cells (if they exist).  \n\n2. If `queries[i]` is less than or equal to the value of the current cell, then:  \n   - We cannot proceed further from this cell.  \n   - The process for this query terminates immediately.  \n\nThe final result for `queries[i]` is the number of unique cells we were able to collect points from.\n\n> Note: Each query starts independently, meaning that the traversal for one query does not affect the traversal for another.\n\nAnother difficult but extremely practical way to phrase this problem is to imagine you're at a buffet, where you can only eat dishes that are under a certain calorie count. Each dish represents a number in the grid, and your queries are your calorie limits. You want to know how many dishes you can indulge in without exceeding your limit. The algorithm helps you quickly determine how many dishes fit your criteria, allowing you to make the most of your buffet experience! Sometimes, the representation of data is more important than the data itself.  \n\nTo solve this problem, we need a solid understanding of BFS, priority queues, and disjoint union. While we will explain the application of these concepts, we will not go in-depth into their theoretical aspects and their basic structure.  \n\nFor a deeper understanding of the theory or to learn how the general conceptual implementation works, please check out the following explore cards:  \n- [BFS and Priority Queue](https://leetcode.com/explore/featured/card/graph/620/breadth-first-search-in-graph/)  \n- [Union Find](https://leetcode.com/explore/learn/card/graph/618/disjoint-set/)  \n- [Binary Search](https://leetcode.com/explore/learn/card/binary-search/)  \n\n---\n\n### Approach 1: Brute Force (TLE)\n\n#### Intuition\n\nFor each query value, we need to determine how many cells in the grid have a value strictly less than the query while ensuring we only move to adjacent cells. This naturally forms a graph traversal problem where each cell is treated as a node connected to its adjacent cells. Since we are interested in finding all reachable nodes that satisfy a condition, Breadth-First Search (BFS) is a suitable choice. BFS explores all nodes at the current level before moving to the next, ensuring we do not miss any reachable cells that meet the criteria.  \n\nFor each query, we begin at the `(0,0)` cell and initialize a queue for BFS traversal. We also maintain a `visited` boolean matrix to ensure we do not revisit cells. The traversal continues as long as there are unprocessed cells in the queue. At each step, we check if the current cellâ€™s value is greater than or equal to the query value. If it is, we cannot proceed further from this cell. Otherwise, we count the cell as visited, increment our result, and attempt to move to its four adjacent cells (up, down, left, and right). Any adjacent cell that has not been visited and has a value strictly less than the query is added to the queue.  \n\nSince each query is independent, we repeat this process for each of them. The final result for each query is the total number of unique cells that we were able to visit while following the movement constraints.\n\n#### Algorithm\n\n- Get the number of rows (`rowCount`) and columns (`colCount`) in `grid`.\n- Initialize `result` array to store the number of points for each query.\n- Define `DIRECTIONS` array to facilitate movement in four directions.\n\n- Iterate over each query:\n  - Extract `queryValue` from `queries`.\n  - Initialize a BFS queue starting from `(0,0)`.\n  - Create a `visited` matrix to track visited cells and mark `(0,0)` as visited.\n  - Initialize `points` to count valid cells.\n\n  - Perform BFS:\n    - Get the current queue size to process all elements at this level.\n    - Iterate over the queue:\n      - Extract `currentRow` and `currentCol` from the front.\n      - If `grid[currentRow][currentCol] >= queryValue`, skip processing.\n      - Otherwise, increment `points`.\n      - Explore four possible directions:\n        - Compute `newRow` and `newCol` as the adjacent cell.\n        - If within bounds, not visited, and value is `< queryValue`, mark `(newRow, newCol)` as visited and add it to the queue.\n\n  - Store `points` in `result` at the corresponding query index.\n\n- Return `result`, containing the count of valid points for each query.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ and $m$ be the number of rows and columns in the grid, respectively, and $k$ be the number of queries.\n\n> $n \\cdot m$ is basically the total number of cells in the grid.\n\n- Time complexity: $O(k \\cdot n \\cdot m)$\n\n    The outer loop runs $k$ times, once for each query. In each iteration, a BFS is performed on the grid. In the worst case, the BFS will visit every cell in the grid, which is $n \\cdot m$ cells. Therefore, the time complexity for each query is $O(n \\cdot m)$, and for all queries, it becomes $O(k \\cdot n \\cdot m)$.\n\n    > Note: The exploration of 4 directions for each cell contributes a constant factor, which does not change the overall time complexity.\n\n- Space complexity: $O(n \\cdot m)$\n\n    The space complexity is dominated by the `visited` matrix, which is of size $n \\cdot m$. This matrix is used to keep track of visited cells during the BFS traversal. \n\n    The BFS queue can also hold up to $n \\cdot m$ cells in the worst case (e.g., when all cells are part of the BFS traversal). Therefore, the overall space complexity is $O(n \\cdot m)$.\n\n    The `DIRECTIONS` array and other variables use constant space and do not significantly impact the overall space complexity.\n  \n---\n\n### Approach 2: Sorting Queries + Min-Heap Expansion\n\n#### Intuition\n\nIn the brute force approach, we restart the search from the top-left corner for every query, treating each query as an independent problem. This results in a significant amount of redundant work because many queries share overlapping information. If a smaller query has already determined that certain cells are accessible, then a larger query should be able to reuse that information instead of starting from scratch. This suggests that instead of treating each query separately, we can process them in an order that allows us to build on previously discovered results, avoiding unnecessary recomputation.  \n\nA natural way to achieve this is to **sort the queries in increasing order** while keeping track of their original indices. By doing this, we ensure that when we process a query, all smaller queries have already been resolved. This allows us to maintain a growing region of accessible cells rather than restarting the search for each query.  \n\nTo efficiently manage this expanding region, we use a **min-heap (priority queue)**. The heap allows us to always expand from the lowest-value cell first, ensuring that we process cells in the correct order. We begin by inserting the top-left cell `(grid[0][0], (0,0))` into the heap. \n\nAs long as the smallest cell in the heap has a value less than the current query, we remove it from the heap, mark it as visited, and attempt to expand outward by pushing all its unvisited neighbors into the heap. Since the heap maintains the smallest-value cell at the top, this ensures that we always expand the lowest-value region before moving to higher values. If the smallest cell's value is greater than or equal to the current query's value, we store the current count of reachable cells in the answer array and continue expanding with the next query's value as the new threshold.\n\nBy the time we process a query, all the cells that could have been visited with smaller query values have already been handled. This allows us to directly store the number of reachable cells without restarting the traversal. Instead of performing redundant BFS searches for each query, we maintain a continuous expansion process, ensuring that each cell is processed only once.  \n\n#### Algorithm\n\n- Get the number of rows (`rowCount`) and columns (`colCount`) in `grid`.\n- Initialize `result` array to store the number of points for each query.\n- Define `DIRECTIONS` array to facilitate movement in four directions.\n- Create a `sortedQueries` array to store queries along with their original indices.\n- Sort `sortedQueries` by query values in ascending order.\n\n- Initialize a min-heap (`minHeap`) to expand cells in increasing order of `grid` values.\n- Create a `visited` matrix to track processed cells and mark `(0,0)` as visited.\n- Push `{grid[0][0], {0, 0}}` into `minHeap` to start expansion.\n- Initialize `totalPoints` to count valid cells.\n\n- Iterate over sorted queries:\n  - Extract `queryValue` and `queryIndex`.\n  - Expand cells while `minHeap` contains values `< queryValue`:\n    - Pop the smallest `cellValue` and its position.\n    - Increment `totalPoints`.\n    - Explore four possible directions:\n      - Compute `newRow` and `newCol` as the adjacent cell.\n      - If within bounds and not visited, push `{grid[newRow][newCol], {newRow, newCol}}` into `minHeap` and mark the cell as visited.\n  - Store `totalPoints` in `result` at the corresponding query index.\n\n- Return `result`, containing the count of valid points for each query.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ and $m$ be the number of rows and columns in the grid, respectively, and $k$ be the number of queries.\n\n> $n \\cdot m$ is basically the total number of cells in the grid.\n\n- Time complexity: $O(k \\log k + n \\cdot m \\log (n \\cdot m))$\n\n    The algorithm first sorts the `k` queries, which takes $O(k \\log k)$ time. Then, for each query, it processes cells using a min-heap. In the worst case, all $n \\cdot m$ cells are processed and pushed into the heap. Each heap operation (push or pop) takes $O(\\log (n \\cdot m))$ time. Therefore, processing all cells takes $O(n \\cdot m \\log (n \\cdot m))$.\n\n    Combining these, the overall time complexity is $O(k \\log k + n \\cdot m \\log (n \\cdot m))$.\n\n    > Note: The exploration of 4 directions for each cell contributes a constant factor which does not change the overall time complexity.\n\n- Space complexity: $O(n \\cdot m + k)$\n\n    The space complexity is dominated by:\n    1. The `visited` matrix, which is of size $n \\cdot m$.\n    2. The min-heap, which can hold up to $n \\cdot m$ cells in the worst case.\n    3. The `sortedQueries` vector, which stores `k` pairs of values and indices.\n\n    Therefore, the overall space complexity is $O(n \\cdot m + k)$.\n\n    The `DIRECTIONS` array and other variables use constant space and do not significantly impact the overall space complexity.\n  \n---\n\n### Approach 3: Using Priority Queue with Binary Search\n\n#### Intuition\n\nIn the previous approach, we processed queries sequentially and used a min-heap to expand the reachable region in increasing order, allowing us to efficiently determine the number of points collected for each query. In this approach, we will separate the precomputation step from the answer calculation to improve algorithmic clarity.\n\nTo implement this, we can preprocess the grid **once** and store the results in a structured way so that queries can be answered in constant or logarithmic time. The key insight is that every cell in the grid has a **minimum value threshold** that must be met in order for it to be reached. If we can determine the smallest query value required to reach each number of points, we can use **binary search** to efficiently answer all queries.  \n\nSo we will begin by treating this as a shortest-path problem where we want to determine the minimum \"effort\" required to reach each cell. We can use **Dijkstraâ€™s algorithm** with a min-heap to explore the grid in order of increasing cost. Each cell `(i, j)` is processed in order of its minimum required value, and we update its neighbors with the maximum value seen along the way. This ensures that we always determine the optimal way to reach a cell.  \n\nThus, our approach will be divided into three key steps:\n1. Reformulating the Problem as a Shortest-Path Search  \n2. Running Dijkstraâ€™s Algorithm\n3. Answering Queries Using Binary Search  \n\n##### **Step 1: Reformulating the Problem as a Shortest-Path Search**  \n\nInstead of handling each query separately, we treat the grid as a **weighted graph** where each cell `(i, j)` has a weight equal to `grid[i][j]`. The goal is to expand outwards from `(0,0)`, adding cells in increasing order of their values. We need to determine **the minimum effort required to reach each cell**, which means that a Dijkstra-like algorithm is appropriate.  \n\nWe use a min-heap (priority queue) to always expand the cell with the lowest current value. Each time we expand to a new cell, we record the maximum value encountered along that path. This ensures that we always determine the optimal way to reach a cell before processing its neighbors.  \n\nTo keep track of how many points can be collected for any given query threshold, we maintain an array `thresholdForMaxPoints`, where `thresholdForMaxPoints[k]` stores the **smallest query value** required to collect `k` points.  \n\n##### **Step 2: Running Dijkstraâ€™s Algorithm** \n\nWe begin by initializing a min-heap with the starting cell `(0,0)`, assigning it a value equal to `grid[0][0]`. This heap will allow us to always expand towards the next reachable cell with the smallest value, ensuring that we process cells in the correct order.  \n\nAs we expand outward, we repeatedly extract the smallest value from the heap, which represents the next cell to be processed. From there, we attempt to move to the neighboring cells, as long as they are not already visitedâ€” this guarantees that we always find the optimal path to reach it.  \n\nFor each newly reached cell `(i, j)`, we compute the minimum threshold required to access it. This is determined by taking the maximum value encountered along the path leading to that cell. In other words, we track the largest value that must be surpassed in order to reach `(i, j)`.  \n\nAs we continue expanding, we maintain an array `thresholdForMaxPoints`, where each entry records the smallest query value required to collect a given number of points. Each time we reach a new cell, we store its threshold in this array, associating it with the number of cells we have accessed so far.  \n\nBy the end of this process, `thresholdForMaxPoints[k]` holds the **minimum query value** needed to collect exactly `k` points. \n\n##### **Step 3: Answering Queries Using Binary Search**  \n\nOnce we have preprocessed the grid, answering a query reduces to a simple binary search on `thresholdForMaxPoints`. Since we stored thresholds in increasing order, binary search allows us to determine in **logarithmic time** how many points can be collected for a given query.  \n\nFor a query `threshold`, we search for the **largest index `k`** such that `thresholdForMaxPoints[k] < threshold`. The answer to the query is simply `k`, the number of points that can be collected.\n\nThe algorithm is visualized below:\n\n!?!../Documents/2503/approach3.json:630,940!?! \n\n#### Algorithm\n\n- Define `DIRECTIONS` to facilitate movement in four directions.\n- Initialize `result` array to store the number of points for each query.\n- Get `rowCount` and `colCount` from `grid`, compute `totalCells = rowCount * colCount`.\n- Create `thresholdForMaxPoints`, where index `i` stores the minimum query value required to reach `i` cells.\n- Create `minValueToReach`, where `minValueToReach[i][j]` holds the maximum value encountered to reach `(i, j)`, initialized to `MAX_VALUE`.\n\n- Run Dijkstraâ€™s algorithm:\n  - Use `minHeap` (min-priority queue) to explore cells in increasing order of encountered values.\n  - Start from `(0,0)`, setting `minValueToReach[0][0] = grid[0][0]` and pushing it into `minHeap`.\n  - While `minHeap` is not empty:\n    - Extract the cell with the smallest encountered value.\n    - Store the encountered value in `thresholdForMaxPoints[++visitedCells]`.\n    - Explore four possible directions:\n      - If the adjacent cell `(newRow, newCol)` is within bounds and unvisited:\n          - Update its `minValueToReach` as the maximum of the value to reach the current cell and  `grid[newRow][newCol]`.\n          - Push it into `minHeap`.\n\n- Process queries using binary search:\n  - For each `queries[i]`, find the rightmost `mid` where `thresholdForMaxPoints[mid] < threshold`.\n  - Initialize `left = 0`, `right = totalCells`.\n  - Perform binary search:\n    - Compute `mid = (left + right + 1) / 2`.\n    - If `thresholdForMaxPoints[mid] < threshold`, move `left = mid`.\n    - Otherwise, adjust `right = mid - 1`.\n  - Store `left` in `result[i]`.\n\n- Return `result`, containing the number of points collected for each query.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ and $m$ be the number of rows and columns in the grid, respectively, and $k$ be the number of queries.\n\n> $n \\cdot m$ is basically the total number of cells in the grid.\n\n- Time complexity: $O(n \\cdot m \\log (n \\cdot m) + k \\log (n \\cdot m))$\n\n    The algorithm uses a min-heap to perform a modified Dijkstra's traversal. In the worst case, all $n \\cdot m$ cells are processed, and each heap operation (insertion or extraction) takes $O(\\log (n \\cdot m))$ time. Therefore, the time complexity for this part is $O(n \\cdot m \\log (n \\cdot m))$.\n\n    For each of the `k` queries, a binary search is performed on the `thresholdForMaxPoints` array, which has a size of $(n \\cdot m) + 1$. Each binary search operation takes $O(\\log (n \\cdot m))$ time. Therefore, the time complexity for this part is $O(k \\log (n \\cdot m))$.\n\n    Combining these, the overall time complexity is $O(n \\cdot m \\log (n \\cdot m) + k \\log (n \\cdot m))$.\n\n- Space complexity: $O(n \\cdot m)$\n\n    The space complexity is dominated by:\n    - The `minHeap`, which can hold up to $n \\cdot m$ cells.\n    - The `minValueToReach` matrix, which is of size $n \\cdot m$.\n    - The `thresholdForMaxPoints` array, which is of size $(n \\cdot m) + 1$.\n\n    Therefore, the overall space complexity is $O(n \\cdot m)$.\n\n---\n\n\n### Approach 4: Disjoint Set Union (Union-Find)  \n\n#### Intuition\n\nInstead of handling queries one by one, we can take a different approach where we process all grid cells first and answer queries afterward. This allows us to efficiently determine the number of reachable points for each query without having to traverse the grid multiple times.\n\nTo better understand this approach, let's reiterate our previous observation in a slightly different way. Think about what each query is asking. A query provides a threshold value and asks how many cells in the grid can be reached from the top-left corner `(0,0)`, while ensuring that all visited cells have values strictly less than this threshold. Instead of iterating over the grid every time a query is given, we can reverse the problem: first process the grid in increasing order of cell values, then efficiently answer all queries using this precomputed information. \n\nTo do this, we first extract all the grid cells and sort them in ascending order based on their values. By processing these cells in this order, we can simulate how the reachable area grows as the threshold increases. We maintain a **disjoint set union (Union-Find) data structure** to dynamically merge connected components as we encounter new cells with increasing values.  \n\nAs we iterate through the sorted grid cells, we add each cell to our Union-Find structure. Whenever we add a cell, we also check its four adjacent neighbors (up, down, left, and right). If a neighbor has already been processed, we merge the current cell with its neighboring cell in the Union-Find structure. This ensures that, at any given moment, all connected components represent regions of the grid where all cells have values strictly less than the current threshold.  \n\nAt the same time, we also sort the queries in ascending order based on their values. As we process each query, we continue adding cells to our Union-Find structure until the current cell values reach or exceed the query threshold. Once we finish adding all the relevant cells for a query, we determine how many of these cells are reachable from `(0,0)`. Since the Union-Find structure keeps track of the size of connected components, we can efficiently find the number of reachable cells by checking the size of the component that contains `(0,0)`.  \n\nIf the query value is greater than `grid[0][0]`, then the number of reachable cells is simply the size of the connected component containing `(0,0)`. Otherwise, no additional cells are reachable, and the answer for this query is `0`.  \n\n#### Algorithm\n\n- Define `Cell(row, col, value)` to represent grid cells and `Query(index, value)` to store queries with their original indices.\n- Initialize `ROW_DIRECTIONS` and `COL_DIRECTIONS` for moving in four directions.\n- Extract `rowCount` and `colCount`, compute `totalCells = rowCount * colCount`.\n\n- Sort queries:\n  - Store each query as a `Query` object in `sortedQueries`.\n  - Sort `sortedQueries` based on `value` in ascending order.\n\n- Sort grid cells:\n  - Store each cell as a `Cell` object in `sortedCells`.\n  - Sort `sortedCells` based on `value` in ascending order.\n\n- Initialize `UnionFind` data structure for dynamic connectivity.\n\n- Process queries:\n  - Iterate over `sortedQueries`, maintaining an index `cellIndex` to track which cells have been processed.\n  - While `sortedCells[cellIndex].value < query.value`, mark the cell as processed and merge it with already processed adjacent cells using `UnionFind.union()`.\n  - Compute the size of the connected component containing `(0,0)`, storing the result for `query.index`.\n\n- Return `result`, containing the number of points collected for each query.\n\n##### **`UnionFind` Class:**\n\n- Define `UnionFind` class for disjoint set operations.\n- Declare `parent` array to track the representative of each set.\n- Declare `size` array to store the size of each set.\n\n- Constructor (`UnionFind(int n)`):\n  - Initialize `parent` with `-1`, indicating each element is its own set.\n  - Initialize `size` to `1`, as each set initially has one element.\n\n- `find(int node)`: Implements path compression to optimize lookup.\n  - If `parent[node]` is `-1`, it is the root and returned.\n  - Otherwise, recursively find the root and apply path compression (`parent[node] = find(parent[node])`).\n\n- `union(int nodeA, int nodeB)`:\n  - Find roots of `nodeA` and `nodeB`.\n  - If both nodes share the same root, they are already in the same set, return `false`.\n  - Otherwise, perform union by size:\n    - Attach the smaller tree to the larger tree.\n    - Update `size` accordingly.\n  - Return `true` to indicate a successful union.\n\n- `getSize(int node)`:\n  - Find the root of `node` and return the size of its set.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ and $m$ be the number of rows and columns in the grid, respectively, and $k$ be the number of queries.\n\n> $n \\cdot m$ is basically the total number of cells in the grid.\n\n- Time complexity: $O(k \\log k + (n \\cdot m) \\log (n \\cdot m) + k \\cdot \\alpha(n \\cdot m))$\n\n    The time complexity arises from several steps. First, sorting the `queries` array takes $O(k \\log k)$. Second, sorting the `sortedCells` array takes $O((n \\cdot m) \\log (n \\cdot m))$. Finally, processing each query involves iterating through the cells and performing union-find operations. \n    \n    The union-find operations, with path compression and union by size, have an amortized time complexity of $O(\\alpha(n \\cdot m))$, where $\\alpha$ is the inverse Ackermann function (practically constant). \n    \n    Since we process up to `totalCells` cells for each query, the total time for all queries is $O(k \\cdot \\alpha(n \\cdot m))$. Combining these, the overall time complexity is $O(k \\log k + (n \\cdot m) \\log (n \\cdot m) + k \\cdot \\alpha(n \\cdot m))$.\n\n- Space complexity: $O((n \\cdot m) + k)$\n\n    The space complexity is dominated by the `sortedQueries` array, which takes $O(k)$ space, the `sortedCells` array, which takes $O(n \\cdot m)$ space, and the `UnionFind` data structure, which uses $O(n \\cdot m)$ space for the `parent` and `size` arrays. Therefore, the overall space complexity is $O((n \\cdot m) + k)$.\n\n---"
}