{
  "title": "All Ancestors of a Node in a Directed Acyclic Graph",
  "problem_id": "1431",
  "frontend_id": "2192",
  "difficulty": "Medium",
  "problem_slug": "all-ancestors-of-a-node-in-a-directed-acyclic-graph",
  "topics": [
    "Depth-First Search",
    "Breadth-First Search",
    "Graph",
    "Topological Sort"
  ],
  "description": "You are given a positive integer n representing the number of nodes of a Directed Acyclic Graph (DAG). The nodes are numbered from 0 to n - 1 (inclusive).\nYou are also given a 2D integer array edges, where edges[i] = [fromi, toi] denotes that there is a unidirectional edge from fromi to toi in the graph.\nReturn a list answer, where answer[i] is the list of ancestors of the ith node, sorted in ascending order.\nA node u is an ancestor of another node v if u can reach v via a set of edges.\nExample 1:\nExample 2:\nConstraints:",
  "examples": [
    {
      "example_num": 1,
      "example_text": "Input: n = 8, edgeList = [[0,3],[0,4],[1,3],[2,4],[2,7],[3,5],[3,6],[3,7],[4,6]]\nOutput: [[],[],[],[0,1],[0,2],[0,1,3],[0,1,2,3,4],[0,1,2,3]]\nExplanation:\nThe above diagram represents the input graph.\n- Nodes 0, 1, and 2 do not have any ancestors.\n- Node 3 has two ancestors 0 and 1.\n- Node 4 has two ancestors 0 and 2.\n- Node 5 has three ancestors 0, 1, and 3.\n- Node 6 has five ancestors 0, 1, 2, 3, and 4.\n- Node 7 has four ancestors 0, 1, 2, and 3.",
      "images": [
        "https://assets.leetcode.com/uploads/2019/12/12/e1.png"
      ]
    },
    {
      "example_num": 2,
      "example_text": "Input: n = 5, edgeList = [[0,1],[0,2],[0,3],[0,4],[1,2],[1,3],[1,4],[2,3],[2,4],[3,4]]\nOutput: [[],[0],[0,1],[0,1,2],[0,1,2,3]]\nExplanation:\nThe above diagram represents the input graph.\n- Node 0 does not have any ancestor.\n- Node 1 has one ancestor 0.\n- Node 2 has two ancestors 0 and 1.\n- Node 3 has three ancestors 0, 1, and 2.\n- Node 4 has four ancestors 0, 1, 2, and 3.",
      "images": [
        "https://assets.leetcode.com/uploads/2019/12/12/e2.png"
      ]
    }
  ],
  "constraints": [
    "1 <= n <= 1000",
    "0 <= edges.length <= min(2000, n * (n - 1) / 2)",
    "edges[i].length == 2",
    "0 <= fromi, toi <= n - 1",
    "fromi != toi",
    "There are no duplicate edges.",
    "The graph is directed and acyclic."
  ],
  "follow_ups": [],
  "hints": [
    "Consider how reversing each edge of the graph can help us.",
    "How can performing BFS/DFS on the reversed graph help us find the ancestors of every node?"
  ],
  "code_snippets": {
    "cpp": "class Solution {\npublic:\n    vector<vector<int>> getAncestors(int n, vector<vector<int>>& edges) {\n        \n    }\n};",
    "java": "class Solution {\n    public List<List<Integer>> getAncestors(int n, int[][] edges) {\n        \n    }\n}",
    "python": "class Solution(object):\n    def getAncestors(self, n, edges):\n        \"\"\"\n        :type n: int\n        :type edges: List[List[int]]\n        :rtype: List[List[int]]\n        \"\"\"\n        ",
    "python3": "class Solution:\n    def getAncestors(self, n: int, edges: List[List[int]]) -> List[List[int]]:\n        ",
    "c": "/**\n * Return an array of arrays of size *returnSize.\n * The sizes of the arrays are returned as *returnColumnSizes array.\n * Note: Both returned array and *columnSizes array must be malloced, assume caller calls free().\n */\nint** getAncestors(int n, int** edges, int edgesSize, int* edgesColSize, int* returnSize, int** returnColumnSizes) {\n    \n}",
    "csharp": "public class Solution {\n    public IList<IList<int>> GetAncestors(int n, int[][] edges) {\n        \n    }\n}",
    "javascript": "/**\n * @param {number} n\n * @param {number[][]} edges\n * @return {number[][]}\n */\nvar getAncestors = function(n, edges) {\n    \n};",
    "typescript": "function getAncestors(n: number, edges: number[][]): number[][] {\n    \n};",
    "php": "class Solution {\n\n    /**\n     * @param Integer $n\n     * @param Integer[][] $edges\n     * @return Integer[][]\n     */\n    function getAncestors($n, $edges) {\n        \n    }\n}",
    "swift": "class Solution {\n    func getAncestors(_ n: Int, _ edges: [[Int]]) -> [[Int]] {\n        \n    }\n}",
    "kotlin": "class Solution {\n    fun getAncestors(n: Int, edges: Array<IntArray>): List<List<Int>> {\n        \n    }\n}",
    "dart": "class Solution {\n  List<List<int>> getAncestors(int n, List<List<int>> edges) {\n    \n  }\n}",
    "golang": "func getAncestors(n int, edges [][]int) [][]int {\n    \n}",
    "ruby": "# @param {Integer} n\n# @param {Integer[][]} edges\n# @return {Integer[][]}\ndef get_ancestors(n, edges)\n    \nend",
    "scala": "object Solution {\n    def getAncestors(n: Int, edges: Array[Array[Int]]): List[List[Int]] = {\n        \n    }\n}",
    "rust": "impl Solution {\n    pub fn get_ancestors(n: i32, edges: Vec<Vec<i32>>) -> Vec<Vec<i32>> {\n        \n    }\n}",
    "racket": "(define/contract (get-ancestors n edges)\n  (-> exact-integer? (listof (listof exact-integer?)) (listof (listof exact-integer?)))\n  )",
    "erlang": "-spec get_ancestors(N :: integer(), Edges :: [[integer()]]) -> [[integer()]].\nget_ancestors(N, Edges) ->\n  .",
    "elixir": "defmodule Solution do\n  @spec get_ancestors(n :: integer, edges :: [[integer]]) :: [[integer]]\n  def get_ancestors(n, edges) do\n    \n  end\nend"
  },
  "solution": "[TOC]\n\n## Solution\n\n---\n\n### Overview\n\nWe are given a directed acyclic graph of `n` nodes, and our task is to return a list where each sub-list contains the ancestors of the node at that index, sorted in ascending order.\n\nA [Directed Acyclic Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) is a graph where each edge has a defined direction from one vertex to another and following these edges will never create a closed loop.\n\nA prerequisite for solving this problem is knowledge of graph traversals, namely depth-first search and breadth-first search. If you are not familiar with popular graph traversal techniques, we strongly encourage you to check out this LeetCode [Explore Card](https://leetcode.com/explore/learn/card/graph/).\n    \n---\n\n### Approach 1: Depth First Search (Reversed Graph)\n\n#### Intuition\n\nA node `u` is an ancestor of node `v` if we can reach `v` by following a series of directed edges from `u`. Thus, all nodes from which we can reach `v` are its ancestors. But how can we efficiently find all ancestors for each node?\n\nThe brute force strategy to determine if node `u` is an ancestor of node `v` involves performing a graph traversal from `u` to check if `v` can be reached. However, this approach has a time complexity of $O(n^3)$, which is too slow for our constraints. We need a more optimized technique.\n\nThe key insight lies in reversing the traversal direction. By starting from each node and tracing back to all its ancestors directly, we can simplify our task. This is achieved by reversing the edges of the graph, flipping parent-child connections to child-parent. Consequently, nodes reachable from a given node in the reversed graph were its ancestors in the original graph. Have a look at the slides below:\n\n!?!../Documents/2192/reversed_slideshow.json:1162,1142!?!\n\nTo find the descendants of a node `v`, we start a depth-first traversal from `v` in the reversed graph, using a `visited` set to track nodes. After the traversal, we collect all nodes in `visited` (except `v`) in a list, representing the ancestors of `v` in the original graph. Performing this traversal for each node provides the required ancestors for all nodes.\n\n#### Algorithm\n\n1. Main method `getAncestors`:\n   - Initialize `adjacencyList` to store the graph representation.\n   - Add the edges to the `adjacencyList` but reverse their direction.\n   - Initialize a list of lists `ancestorsList` to store the ancestors of each node.\n   - Iterate through each node:\n     - Initialize:\n       - An empty list `ancestors` to store ancestors of the current node.\n       - A set `visited` to store the nodes already visited in the traversal.\n     - Call the `findChildren` method to perform DFS and find all descendants of the current node.\n     - Add all nodes present in the `visited` set to `ancestors`.\n     - Add `ancestors` to `ancestorsList`.\n   - Return `ancestorsList` containing the ancestors for each node.\n  \n2. Helper method `findChildren`:\n   - Define the `findChildren` method with parameters: `currentNode`, `adjacencyList` and the `visited` set for the current traversal.\n   - Add `currentNode` to the `visited` set.\n   - Iterate through the neighbors of `currentNode`. If `neighbor` has not been visited yet:\n     - Recursively call `findChildren` on `neighbor`.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ be the number of vertices in the graph and $m$ be the length of the `edges` array. \n\n- Time complexity: $O(n^2 + n \\cdot m)$\n\n    Initializing and populating the adjacency list requires $O(n + m)$ time.\n\n    The algorithm calls the the DFS method a total of $n$ times. The depth-first search has a worst-case time complexity of $O(n + m)$. Thus, finding the ancestors take a total of $O(n^2 + n \\cdot m)$. \n\n    Forming the list of ancestors requires $O(n)$ time, which also occurs $n$ times. This equates to a $O(n^2)$ complexity.\n\n    Thus, the total time complexity is $O(n + m)$ + $O(n^2 + n \\cdot m)$ + $O(n^2)$, which simplifies to $O(n^2 + n \\cdot m)$.\n\n- Space complexity: $O(n + m)$\n\n    The adjacency list takes $O(n + m)$ space, while the `ancestors` list and the `visited` set each require $O(n)$ space. The recursion call stack can go as deep as $O(n)$ in the worst case. Thus, the total space complexity of the algorithm is $O(n + m) + 3 \\cdot O(n)$, which simplifies to $O(n + m)$.\n\n    > Note: We are not considering the space required by `ancestorsList` in our analysis, since it is part of the output space. If we do consider it, `ancestorsList` would have a worst-case space complexity of $O(n^2)$, making the space complexity of the algorithm $O(n^2 + m)$.\n\n---\n\n### Approach 2: Depth First Search (Optimized)\n\n#### Intuition\n\nWe can solve this problem without reversing the edges. Observe that a vertex `v` will be an ancestor for all nodes reachable from it. Therefore, we can initiate a depth-first traversal from each vertex and designate that vertex as an ancestor to all nodes it can reach.\n\nOur depth-first search would be very similar to Approach 1; but with a key difference: we add the given node as an `ancestor` to all children of the node we're currently exploring. We then recursively call our depth-first search function on each child until all descendants of `ancestor` are marked with its presence. \n\nHave a look at this slideshow to better understand this process:\n\n!?!../Documents/2192/ancestors_slideshow.json:1742,1310!?!\n\nAnother optimization we can implement is eliminating the `visited` set. In each traversal, we add `ancestor` to the list of ancestors for each node. To determine if a node has been visited, we check if its last ancestor matches the current ancestor. If it does, the node has been visited and can be safely skipped from further exploration.\n\n#### Algorithm\n\n1. Main method **getAncestors**:\n   - Initialize: \n     - A list of lists `adjacencyList` to store the adjacency list of the graph.\n     - A list of lists `ancestors` to store the ancestors of each node.\n   - Populate `adjacencyList` with edges from the input.\n   - For each node, use depth-first search (DFS) to find all its ancestors.\n   - Return `ancestors` containing the ancestors of each node.\n  \n2. Helper method **findAncestorsDFS**:\n   - Define a method `findAncestorsDFS` that takes four parameters: the `ancestor` node, `adjacencyList`, the current node being visited, and `ancestors`.\n   - Loop through each child node `childNode` of the current node in the adjacency list:\n     - Check if `ancestor` is already added to the child node's ancestor list. If not:\n       - Add `ancestor` to the child node's ancestor list.\n       - Recursively call `findAncestorsDFS` for `childNode`.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ be the number of vertices in the graph and $m$ be the length of the `edges` array. \n\n- Time complexity: $O(n^2 + n \\cdot m)$\n\n    Initializing and populating the adjacency list requires $O(n + m)$ time.\n    \n    The depth-first search (DFS) has a time complexity of $O(n + m)$ and is executed $n$ times. Therefore, the total time complexity of this section is $O(n^2 + n \\cdot m)$.\n    \n    The overall time complexity of the algorithm combines $O(n + m)$ for initialization and $O(n^2 + n \\cdot m)$ for the DFS, resulting in $O(n^2 + n \\cdot m)$ complexity.\n\n- Space complexity: $O(n + m)$\n\n    The adjacency list representation of the graph takes $O(n + m)$ space. The call stack for the DFS could go as deep as the height of the graph, which in the worst case is $O(n)$. Thus, the total space complexity of the algorithm is $O(n + m) + O(n)$, simplifying to $O(n + m)$.\n\n    > Note: We have not considered the space required by `ancestors` in our analysis, since it is part of the output space.\n\n---\n\n### Approach 3: Topological Sort (BFS)\n\n#### Intuition\n\nThe problem revolves around the nature of the graph as a Directed Acyclic Graph (DAG). In a DAG, cycles are absent, and each path progresses clearly from a starting point to an endpoint. This characteristic implies that by processing nodes in a specific order, we can systematically determine each node's ancestors.\n\nThe key to identifying this optimal processing order lies in topological sorting. In a DAG, topological sorting arranges nodes such that for every directed edge from node `u` to node `v`, `u` precedes `v` in the ordering. This arrangement is crucial because it ensures that when we process a node `v`, we have already considered all its potential ancestors. To achieve this ordering, we will use Kahn's algorithm.\n\nKahn's algorithm is a method for topologically sorting a directed acyclic graph. It starts by identifying all nodes without incoming edges and placing them in a queue. At each step, it removes a node from this queue, adds it to the sorted list, and eliminates its outgoing edges from the graph. This process may create new nodes without incoming edges, which are then added to the queue. The algorithm continues until the queue is empty. The resulting list provides a valid topological ordering of the graph. For a more detailed explanation of Kahn's algorithm and its implementation, refer to this [Explore Card](https://leetcode.com/explore/learn/card/graph/623/kahns-algorithm-for-topological-sorting/3886/).\n\nAfter establishing the topological order, we process each node sequentially. For each `node`, we iterate through its `neighbors`, designating both the node itself and its ancestors as ancestors of the `neighbor`. To efficiently track each node's ancestors, we use a list of sets. Sets, unlike lists, maintain unique elements, ensuring each ancestor appears only once in a node's ancestor set.\n\nIn the final step, we'll convert these sets of ancestors into lists, as required by the problem statement.\n\n#### Algorithm\n \n- Initialize a list of lists `adjacencyList` to store the edges of the graph.\n- Initialize an array `indegree` to store the in-degree of each node.\n- Fill `adjacencyList` and the `indegree` array based on the given edges.\n- Initialize a queue `nodesWithZeroIndegree` and add all such nodes to the queue.\n- Initialize a list `topologicalOrder` to store the topological order of nodes and process nodes in the queue. For each node:\n  - Reduce the in-degree of its neighbors. \n  - Add neighbors with zero in-degree to the queue.\n- Initialize a list `ancestorsList` to store the result and a list of sets `ancestorsSetList` to store the ancestors of each node.\n- For each `node` in the topological order:\n  - Loop over all neighbors `neighbor` of `node`. For each `neighbor`:\n    - Add `node` as the immediate parent of `neighbor` to the set `ancestorsSetList[neighbor]`.\n    - Add all other ancestors of `node` to the set `ancestorsSetList[neighbor]`.\n- Add the contents of each set to it's corresponding list in `ancestorsList` in ascending order.\n- Return `ancestorsList`, which contains the ancestors of each node in the graph.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ be the number of vertices in the graph and $m$ be the length of the `edges` array.\n\n* Time complexity: $O(n^2 + m)$\n\n    Creating and filling the adjacency list and in-degree array requires $O(n + m)$ time.\n    \n    Topological sort on the graph also needs $O(n + m)$ time.\n    \n    In the worst-case scenario, if the graph forms a chain, the time complexity could be $O(n^2)$. This is because each node in the chain would have a growing number of ancestors. So, the sizes of the ancestor lists would be $0$, $1$, $2$, ..., $n-2$, $n-1$. Forming these lists would take another $O(n^2)$ time.\n    \n    Thus, the overall time complexity of the algorithm is $O(n^2 + m)$.\n\n* Space complexity: $O(n^2 + m)$\n\n    We use an adjacency list which takes $O(n + m)$ space.\n\n    We store an array of size $n$ to keep track of the indegree of each node, taking $O(n)$ space.\n\n    All nodes are added to the queue once, requiring $O(n)$ space.\n\n    The topological order list requires $O(n)$ space.\n\n    Maintaining a list of sets to store the ancestors requires $O(n^2)$ space in the worst case.\n\n    Considering all individual components, the total space complexity comes out to be $O(n^2 + m)$.\n\n    > Note: As stated in the previous approaches, the space taken by `ancestorsList` is not taken into consideration since it is part of the output space. \n\n---"
}