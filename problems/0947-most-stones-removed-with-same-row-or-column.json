{
  "title": "Most Stones Removed with Same Row or Column",
  "problem_id": "984",
  "frontend_id": "947",
  "difficulty": "Medium",
  "problem_slug": "most-stones-removed-with-same-row-or-column",
  "topics": [
    "Hash Table",
    "Depth-First Search",
    "Union Find",
    "Graph"
  ],
  "description": "On a 2D plane, we place n stones at some integer coordinate points. Each coordinate point may have at most one stone.\nA stone can be removed if it shares either the same row or the same column as another stone that has not been removed.\nGiven an array stones of length n where stones[i] = [xi, yi] represents the location of the ith stone, return the largest possible number of stones that can be removed.\nExample 1:\nExample 2:\nExample 3:\nConstraints:",
  "examples": [
    {
      "example_num": 1,
      "example_text": "Input: stones = [[0,0],[0,1],[1,0],[1,2],[2,1],[2,2]]\nOutput: 5\nExplanation: One way to remove 5 stones is as follows:\n1. Remove stone [2,2] because it shares the same row as [2,1].\n2. Remove stone [2,1] because it shares the same column as [0,1].\n3. Remove stone [1,2] because it shares the same row as [1,0].\n4. Remove stone [1,0] because it shares the same column as [0,0].\n5. Remove stone [0,1] because it shares the same row as [0,0].\nStone [0,0] cannot be removed since it does not share a row/column with another stone still on the plane.",
      "images": []
    },
    {
      "example_num": 2,
      "example_text": "Input: stones = [[0,0],[0,2],[1,1],[2,0],[2,2]]\nOutput: 3\nExplanation: One way to make 3 moves is as follows:\n1. Remove stone [2,2] because it shares the same row as [2,0].\n2. Remove stone [2,0] because it shares the same column as [0,0].\n3. Remove stone [0,2] because it shares the same row as [0,0].\nStones [0,0] and [1,1] cannot be removed since they do not share a row/column with another stone still on the plane.",
      "images": []
    },
    {
      "example_num": 3,
      "example_text": "Input: stones = [[0,0]]\nOutput: 0\nExplanation: [0,0] is the only stone on the plane, so you cannot remove it.",
      "images": []
    }
  ],
  "constraints": [
    "1 <= stones.length <= 1000",
    "0 <= xi, yi <= 104",
    "No two stones are at the same coordinate point."
  ],
  "follow_ups": [],
  "hints": [],
  "code_snippets": {
    "cpp": "class Solution {\npublic:\n    int removeStones(vector<vector<int>>& stones) {\n        \n    }\n};",
    "java": "class Solution {\n    public int removeStones(int[][] stones) {\n        \n    }\n}",
    "python": "class Solution(object):\n    def removeStones(self, stones):\n        \"\"\"\n        :type stones: List[List[int]]\n        :rtype: int\n        \"\"\"\n        ",
    "python3": "class Solution:\n    def removeStones(self, stones: List[List[int]]) -> int:\n        ",
    "c": "int removeStones(int** stones, int stonesSize, int* stonesColSize) {\n    \n}",
    "csharp": "public class Solution {\n    public int RemoveStones(int[][] stones) {\n        \n    }\n}",
    "javascript": "/**\n * @param {number[][]} stones\n * @return {number}\n */\nvar removeStones = function(stones) {\n    \n};",
    "typescript": "function removeStones(stones: number[][]): number {\n    \n};",
    "php": "class Solution {\n\n    /**\n     * @param Integer[][] $stones\n     * @return Integer\n     */\n    function removeStones($stones) {\n        \n    }\n}",
    "swift": "class Solution {\n    func removeStones(_ stones: [[Int]]) -> Int {\n        \n    }\n}",
    "kotlin": "class Solution {\n    fun removeStones(stones: Array<IntArray>): Int {\n        \n    }\n}",
    "dart": "class Solution {\n  int removeStones(List<List<int>> stones) {\n    \n  }\n}",
    "golang": "func removeStones(stones [][]int) int {\n    \n}",
    "ruby": "# @param {Integer[][]} stones\n# @return {Integer}\ndef remove_stones(stones)\n    \nend",
    "scala": "object Solution {\n    def removeStones(stones: Array[Array[Int]]): Int = {\n        \n    }\n}",
    "rust": "impl Solution {\n    pub fn remove_stones(stones: Vec<Vec<i32>>) -> i32 {\n        \n    }\n}",
    "racket": "(define/contract (remove-stones stones)\n  (-> (listof (listof exact-integer?)) exact-integer?)\n  )",
    "erlang": "-spec remove_stones(Stones :: [[integer()]]) -> integer().\nremove_stones(Stones) ->\n  .",
    "elixir": "defmodule Solution do\n  @spec remove_stones(stones :: [[integer]]) :: integer\n  def remove_stones(stones) do\n    \n  end\nend"
  },
  "solution": "[TOC]\n\n## Solution\n\n---\n\n### Overview\n\nWe are given a 2-D plane with `n` stones placed at integer coordinates, where a stone can be removed only if another stone shares either its row or column. Our task is to determine the maximum number of stones that can be removed from the plane under these conditions.\n\n---\n\n### Approach 1: Depth First Search\n\n#### Intuition\n\nTwo stones are considered \"connected\" if they share a row or column, but this connection extends beyond just pairs of stones. If stone A is connected to stone B and stone B is connected to stone C, then all three stones form part of the same group, even if A and C don’t directly share a row or column. This concept is akin to connected components in graph theory, where a connected component is a group of nodes where you can reach any node from any other node in the group. Take a look at the illustration below to visualize the components:\n\n![connected components](../Figures/947_re/components.png)\n\nSince every stone in a connected component shares a row or column with at least one other stone, we can remove all but one stone. The remaining stone cannot be removed as it no longer shares coordinates with any other stone, having eliminated all others in its component.\n\nTherefore, if our 2-D plane contains multiple connected components, each can be reduced to a single stone. The maximum number of stones that can be removed can be mathematically expressed as:\n\n```\nMax removable stones = Total stones - Number of connected components\n```Proof that in a connected component of stones, we can remove all but one stone.Base case: For $n \\leq 2$, the statement is trivially true.\n\n- For $n = 1$, we can't remove any stones.\n- For $n = 2$, we can remove one stone, leaving the other.\n\nInductive hypothesis: Assume the statement holds for all connected components of size $k$ or less, where $k \\geq 2$.\n\nInductive step: Consider a connected component $C$ of size $k + 1$.\n\n1. Choose an arbitrary stone $S$ to keep.\n2. The remaining $k$ stones form $m$ connected sub-components $C_1$, $C_2$, ..., $C_m$, where $1 ≤ m ≤ k$.\n3. Let $s_1$, $s_2$, ..., $s_m$ be the sizes of these sub-components. We know that: $s_1 + s_2 + ... + s_m = k$\n4. For each sub-component $C_i$:\n    1. By the inductive hypothesis, we can remove all but one stone from $C_i$.\n    2. Choose to keep the stone in $C_i$ that is connected to $S$ in the original component $C$.\n5. After applying step 4 to all sub-components, we have removed: $(s_1 - 1) + (s_2 - 1) + ... + (s_m - 1) = (s_1 + s_2 + ... + s_m) - m = k - m$ stones\n6. We are now left with $m + 1$ stones: the $m$ stones we kept from each sub-component, plus our original chosen stone $S$.\n7. Each of these $m$ stones shares either a row or column with $S$ (by our choice in step 4(ii)). Therefore, we can remove these $m$ stones one by one.\n8. In total, we have removed $(k - m) + m = k$ stones, leaving only the originally chosen stone $S$.\n\nConclusion: By the principle of mathematical induction, we've proved that for any connected component of size $n$, we can remove $n - 1$ stones, leaving just one stone.So, our implementation boils down to two parts:\n1. Represent the stones as a graph.\n2. Count the number of connected components in this graph.\n\nFor the first part, we can utilize an adjacency list, where for each stone, we maintain a list of all other stones it's connected to (i.e., shares a row or column with). \n\nFor the second part, we can apply a graph traversal algorithm, such as Depth-First Search (DFS). We start a DFS from an unvisited stone, marking all reachable stones as visited, and count this as one connected component. We repeat this process until all stones are visited. The number of DFS executions will give us the total number of connected components in the grid, after which we can apply the formula above to determine the maximum number of stones that can be removed.\n\n> Note: While we've discussed using depth-first search to explore each connected component, breadth-first search is an equally valid alternative, offering similar time and space complexities.\n\n#### Algorithm\n\nMain method `removeStones`:\n\n- Set `n` as the length of the input array `stones`.\n- Initialize a list of lists `adjacencyList`  with `n` empty lists.\n- Iterate over each stone `i`:\n  - For each stone `i`, iterate over stones `j` from `i+1` to `n-1`:\n    - If `stone[i]` shares the same row (`stones[i][0] == stones[j][0]`) or column (`stones[i][1] == stones[j][1]`) as `stone[j]`:\n      -  Add `j` to the adjacency list of `i` and `i` to the adjacency list of `j`.\n- Initialize a variable `numOfConnectedComponents` to `0`, to keep track of the number of connected components in the graph.\n- Create a boolean array `visited` of length `n` initialized to `false`, to track which stones have been visited during the DFS.\n- Iterate over each stone `i`:\n  - If stone `i` has not been visited, perform a DFS starting from stone `i` to visit all stones in the same connected component.\n  - After the DFS completes, increment `numOfConnectedComponents` by `1`.\n- Return `n - numOfConnectedComponents` as our answer.\n\nHelper method `depthFirstSearch`:\n\n- Define a method `depthFirstSearch` with parameters: `adjacencyList`, `visited`, and the current `stone`.\n- Mark the current `stone` as visited by setting `visited[stone]` to `true`.\n- For each `neighbor` of `stone` in the `adjacencyList`:\n  - If the neighbor has not been visited:\n    - Recursively call `depthFirstSearch` on `neighbor` to visit all stones in the connected component.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ be the length of the `stones` array.\n\n- Time complexity: $O(n^2)$\n\n    The graph is built by iterating over all pairs of stones `(i,j)` to check if they share the same row or column, resulting in $O(n^2)$ time complexity.\n\n    In the worst case, the depth-first search will traverse all nodes and edges. Since each stone can be connected to every other stone, the algorithm can visit all $O(n^2)$ edges across all DFS calls.\n\n    Thus, the overall time complexity of the algorithm is $2 \\cdot O(n^2) = O(n^2)$.\n\n- Space complexity: $O(n^2)$\n\n    In the worst case, any two stones could share the same row or column. So, the `adjacencyList` could store up to $n^2$ edges, taking $O(n^2)$ space.\n\n    The `visited` array takes an additional linear space.\n\n    The recursive DFS call stack can go as deep as the number of stones in a single connected component. In the worst case, this depth could be $n$, leading to $O(n)$ additional space for the stack.\n\n    Thus, the space complexity of the algorithm is $2 \\cdot O(n) + O(n^2) = O(n^2)$.\n\n---\n\n### Approach 2: Disjoint Set Union\n\n#### Intuition\n\nA Disjoint Set Union (or Union-Find) is an efficient data structure for identifying connected components in a graph. It helps us group elements into disjoint sets, determine which set an element belongs to, and efficiently merge sets—exactly what we need here. If you are unfamiliar with DSU, have a look at this LeetCode [Explore Card](https://leetcode.com/explore/learn/card/graph/618/disjoint-set/3881/) for in-depth explanation.\n\nWe begin by treating each stone as a separate set, meaning every stone starts off in its own connected component. Then, we iterate over each pair of stones and merge (union) them if they share a common row or column.\n\nIn our Union-Find data structure, we also maintain a `count`, which keeps track of the total number of separate connected components in the graph. This `count` is initially set to `n`, the total number of stones. Each successful union operation indicates that two separate components have merged into one, so we decrement the `count`.\n\nAfter processing all possible pairs of stones, the value of `n - count` gives us the maximum number of stones that can be removed.\n\n#### Algorithm\n\nMain method `removeStones`:\n \n- Set `n` as the length of the input array `stones`.\n- Initialize a `UnionFind` object `uf` with `n` as the size.\n- Iterate over each stone `i`:\n  - For each `i`, iterate over stones `j` from `i+1` to `n-1`:\n    - If stone `i` shares the same row (`stones[i][0] == stones[j][0]`) or column (`stones[i][1] == stones[j][1]`) as stone `j`:\n      - Perform a `union` operation on `i` and `j`.\n- Return `n - uf.count`.\n\nHelper class `UnionFind`:\n\n- Define a class `UnionFind` with fields: an integer array `parent` and a variable `count`.\n- Override the default constructor:\n  - Initialize `parent` to size `n` with all elements set to `-1`.\n  - Set `count` to `n`, representing the initial number of connected components.\n  \nHelper method `find(node)` [`UnionFind`]:\n\n- If the parent of `node` is `-1`, return `node` as it is its own root.\n- Otherwise, recursively call `find` on `parent[node]`, set its result to `parent[node]` and return it.\n\nHelper method `union(n1, n2)` [`UnionFind`]:\n\n- Find the roots of `n1` and `n2` using the `find` method and store it in `root1` and `root2`, respectively.\n- If `root1` is equal to `root2`, both stones are already in the same connected component, so return.\n- If `root1` and `root2` are different, merge the two components by setting `parent[root1]` to `root2`.\n- Decrement `count`.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ be the length of the `stones` array. \n\n* Time complexity: $O(n^2 \\cdot \\alpha(n))$\n\n    Initializing the `parent` array with `-1` takes $O(n)$ time.\n\n    The nested loops iterate through each pair of stones `(i, j)`. The number of pairs is $\\frac{n(n-1)}{2}$, which is $O(n^2)$.\n\n    For each pair, if the stones share the same row or column, the `union` operation is performed. The `union` (and subsequent `find`) operation takes $O(\\alpha(n))$, where $\\alpha$ is the [inverse Ackermann function](https://www.gabrielnivasch.org/fun/inverse-ackermann).\n\n    Thus, the overall time complexity of the algorithm is $O(n^2 \\cdot \\alpha(n))$.\n\n* Space complexity: $O(n)$\n\n    The only additional space used by the algorithm is the `parent` array, which takes $O(n)$ space.\n\n---\n\n### Approach 3: Disjoint Set Union (Optimized)\n\n#### Intuition\n\nThe most time-consuming part of our previous algorithms has been iterating through every possible pair of stones, but can we do better? \n\nIn our earlier approach, each stone was treated as a distinct entity. In this improved method, we'll break each stone down into two entities: a row index and a column index. Although this effectively doubles the total number of nodes in the graph, it doesn't affect our solution since our goal is to find the number of connected components, not the number of nodes within each component.\n\nWhen we treat the row and column indices as separate entities, all stones that share the same row or column index become implicitly connected, eliminating the need to manually connect these stones. However, we do need to connect the row and column indices of a stone since they were originally part of the same element.\n\nThis optimization condenses our algorithm into a single step: looping through the input array `stones` and unioning the row and column indices of each element. However, this approach introduces two challenges:\n\n1. Differentiating Between Row and Column Elements: \n    If a row and column share the same value, how do we distinguish between them? For instance, consider two stones positioned at (x, y) and (y, z). If we union x with y, and y with z, the Disjoint Set Union (DSU) might incorrectly consider the two stones as connected, which is not necessarily true. To address this, we differentiate between row and column elements by offsetting the column value by a large constant that places it beyond the range of valid row values. We use 10,001 for this purpose, as the range of row indices is [0, 10,000].\n\n2. Counting the Number of Connected Components:\n    Initially, we assumed the number of connected components was `n` since each stone was treated as a separate node. However, in this approach, a stone is no longer the basic unit in the graph. While it might seem logical to consider the number of nodes as twice the number of stones, this assumption is incorrect because row and column indices are likely to be repeated among stones and thus will not form separate nodes in the graph. \n    \n    To accurately track the number of nodes, we maintain a set called `uniqueNodes`. Before performing a union operation, we check if the nodes (row and column) have been encountered before. If not, these are new nodes in the graph and can initially be considered separate components, so we increment our count. If the union operation is successful, we subsequently decrease the count.\n\nAfter all operations are complete, the count will store the number of connected components in the graph.\n\n#### Algorithm\n\nMain method `removeStones`:\n \n- Set `n` as the length of the input array `stones`.\n- Create an instance of the `UnionFind` class `uf` with a size of `20002` to handle the coordinate range.\n- Loop through each stone `i` in `stones`:\n  - Call `uf.union()` to union the x-coordinate (`stones[i][0]`) and the y-coordinate offset by `10001` (`stones[i][1] + 10001`).\n- Return `n - uf.componentCount` as our result.\n\nHelper class `UnionFind`:\n- Define a class `UnionFind` with fields: an integer array `parent`, a variable `componentCount`, and a set `uniqueNodes`.\n- Override the default constructor:\n  - Initialize `parent` to size `n` with all elements set to `-1`.\n  - Set `componentCount` to `0` to track the number of connected components.\n  - Initialize `uniqueNodes` to track which nodes have been processed.\n\nHelper method `find(node)` [`UnionFind`]:\n\n- If `node` is not in `uniqueNodes`:\n  - Increment `componentCount` and add the node to `uniqueNodes`.\n- If the parent of the `node` is `-1`:\n  - Return `node` itself as it is its own parent.\n- Otherwise, recursively call `find` on `parent[node]`, set its result to `parent[node]` and return it.\n\nHelper method `union(n1, n2)` [`UnionFind`]:\n\n- Find the root of `n1` and `n2` using the `find` method and store it in `root1` and `root2`, respectively.\n- If the roots are the same, they are already in the same component, so return.\n- Otherwise, merge the two components by setting `parent[root1]` to `root2`.\n- Decrement `componentCount`.\n\n#### Implementation#### Complexity Analysis\n\nLet $n$ be the length of the `stones` array.\n\n* Time complexity: $O(n)$\n\n    Since the size of the `parent` array is constant (`20002`), initializing it takes constant time. \n    \n    The `union` operation is called `n` times, once for each stone. All `union` and `find` operations take $O(\\alpha(20002)) = O(1)$ time, where $\\alpha$ is the inverse Ackermann function.\n\n    Thus, the overall time complexity is $O(n)$.\n\n* Space complexity: $O(n + 20002)$\n\n    The `parent` array takes a constant space of `20002`.\n\n    The `uniqueNodes` set can have at most $2 \\cdot n$ elements, corresponding to all unique $x$ and $y$ coordinates. The space complexity of this set is $O(n)$.\n\n    Thus, the overall space complexity of the approach is $O(n + 20002)$.\n\n    > While constants are typically excluded from complexity analysis, we've included it here due to its substantial size.\n\n---"
}